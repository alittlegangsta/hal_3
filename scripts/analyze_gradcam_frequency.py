#!/usr/bin/env python3
"""
Grad-CAMé¢‘ç‡åˆ†æè„šæœ¬
å°†ç°æœ‰çš„Grad-CAMç»“æœä¸­çš„å°ºåº¦è½´è½¬æ¢ä¸ºå¯¹åº”çš„é¢‘ç‡ï¼Œå¹¶æå–å¯¹åº”çš„åŸå§‹æ³¢å½¢è¿›è¡Œå¯¹é½åˆ†æ
"""

import os
import sys
import pickle
import torch
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path
import yaml
import cv2
from scipy import signal
import pywt

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.append(str(project_root))

from src.models.cnn_model import HybridCNNModel
from src.models.feature_extractor import FeatureExtractor
from src.visualization.grad_cam import GradCAM
from src.utils.device_utils import get_device


def scale_to_frequency(scales, sampling_period=1e-5, wavelet='morl'):
    """
    å°†CWTå°ºåº¦è½¬æ¢ä¸ºå¯¹åº”çš„é¢‘ç‡
    
    Args:
        scales: CWTå°ºåº¦æ•°ç»„
        sampling_period: é‡‡æ ·å‘¨æœŸ (s)
        wavelet: å°æ³¢ç±»å‹
        
    Returns:
        frequencies: å¯¹åº”çš„é¢‘ç‡æ•°ç»„ (Hz)
    """
    if wavelet == 'morl':
        # Morletå°æ³¢çš„ä¸­å¿ƒé¢‘ç‡
        fc = 1.0  # å½’ä¸€åŒ–çš„Morletå°æ³¢ä¸­å¿ƒé¢‘ç‡
    else:
        # å¯¹äºå…¶ä»–å°æ³¢ï¼Œä½¿ç”¨PyWaveletsçš„ä¸­å¿ƒé¢‘ç‡
        fc = pywt.central_frequency(wavelet)
    
    # å°ºåº¦åˆ°é¢‘ç‡çš„è½¬æ¢å…¬å¼
    frequencies = fc / (scales * sampling_period)
    
    return frequencies


def load_processed_data(azimuth):
    """
    åŠ è½½é¢„å¤„ç†çš„æ•°æ®
    
    Args:
        azimuth: æ–¹ä½æ ‡è¯†ç¬¦
        
    Returns:
        data_dict: åŒ…å«åŸå§‹æ³¢å½¢ã€CWTç‰¹å¾ç­‰çš„å­—å…¸
    """
    try:
        # åŠ è½½é¢„å¤„ç†æ•°æ®
        with open(f'data/processed/full_processed_{azimuth}.pkl', 'rb') as f:
            processed_data = pickle.load(f)
        
        print(f"âœ… æˆåŠŸåŠ è½½æ–¹ä½ {azimuth} çš„é¢„å¤„ç†æ•°æ®")
        print(f"   - CWTç‰¹å¾å½¢çŠ¶: {processed_data['cwt_features'].shape}")
        print(f"   - ç»Ÿè®¡ç‰¹å¾å½¢çŠ¶: {processed_data['stat_features'].shape}")
        print(f"   - æ ‡ç­¾å½¢çŠ¶: {processed_data['labels'].shape}")
        
        return processed_data
        
    except FileNotFoundError:
        print(f"âŒ æœªæ‰¾åˆ°æ–¹ä½ {azimuth} çš„é¢„å¤„ç†æ•°æ®æ–‡ä»¶")
        return None


def reconstruct_original_waveform(cwt_features, stat_features, sample_info):
    """
    åŸºäºCWTç‰¹å¾é‡æ„è¿‘ä¼¼çš„åŸå§‹æ³¢å½¢ï¼ˆç”¨äºæ¼”ç¤ºï¼‰
    
    Args:
        cwt_features: CWTç‰¹å¾
        stat_features: ç»Ÿè®¡ç‰¹å¾
        sample_info: æ ·æœ¬ä¿¡æ¯
        
    Returns:
        waveform: é‡æ„çš„æ³¢å½¢
        time_axis: æ—¶é—´è½´
    """
    # ä»ç»Ÿè®¡ç‰¹å¾ä¸­æå–ä¿¡æ¯
    length = 1024  # æ ‡å‡†æ³¢å½¢é•¿åº¦
    sampling_period = 1e-5  # é‡‡æ ·å‘¨æœŸ
    time_axis = np.arange(length) * sampling_period
    
    # åŸºäºç»Ÿè®¡ç‰¹å¾é‡æ„æ³¢å½¢
    peak_time = stat_features[2] if len(stat_features) > 2 else 0.005
    dominant_freq = stat_features[5] if len(stat_features) > 5 else 5000
    rms = stat_features[1] if len(stat_features) > 1 else 0.1
    
    # åˆ›å»ºåŸºç¡€æ³¢å½¢
    waveform = np.zeros(length)
    
    # æ·»åŠ ä¸»é¢‘åˆ†é‡
    t_shifted = time_axis - peak_time
    envelope = np.exp(-np.abs(t_shifted) * 1000) * (t_shifted >= 0)
    waveform += rms * np.sin(2 * np.pi * dominant_freq * time_axis) * envelope
    
    # æ·»åŠ åŸºäºCWTç‰¹å¾çš„å…¶ä»–åˆ†é‡
    # ä»CWTç‰¹å¾ä¸­æå–èƒ½é‡åˆ†å¸ƒ
    energy_profile = np.mean(cwt_features, axis=0)
    energy_profile = energy_profile / np.max(energy_profile) if np.max(energy_profile) > 0 else energy_profile
    
    # æ·»åŠ è°ƒåˆ¶åˆ†é‡
    for i in range(min(5, len(energy_profile) // 100)):
        freq_component = dominant_freq * (0.5 + 0.5 * i)
        amplitude = rms * 0.3 * energy_profile[i * 100] if i * 100 < len(energy_profile) else 0
        waveform += amplitude * np.sin(2 * np.pi * freq_component * time_axis) * envelope
    
    # æ·»åŠ å™ªå£°
    noise_level = 0.05 * rms
    waveform += np.random.normal(0, noise_level, length)
    
    return waveform, time_axis


def load_gradcam_result(azimuth, sample_num):
    """
    åŠ è½½ç°æœ‰çš„Grad-CAMç»“æœ
    
    Args:
        azimuth: æ–¹ä½æ ‡è¯†ç¬¦
        sample_num: æ ·æœ¬ç¼–å·
        
    Returns:
        gradcam_data: Grad-CAMæ•°æ®å­—å…¸
    """
    gradcam_file = f'data/results/full_gradcam/gradcam_azimuth_{azimuth}_sample_{sample_num}.png'
    
    if not os.path.exists(gradcam_file):
        print(f"âŒ Grad-CAMæ–‡ä»¶ä¸å­˜åœ¨: {gradcam_file}")
        return None
    
    # è¯»å–å›¾ç‰‡ï¼ˆè¿™é‡Œæˆ‘ä»¬éœ€è¦é‡æ–°ç”ŸæˆGrad-CAMæ•°æ®ï¼Œå› ä¸ºPNGæ–‡ä»¶ä¸åŒ…å«åŸå§‹æ•°å€¼ï¼‰
    print(f"âš ï¸  æ£€æµ‹åˆ°ç°æœ‰Grad-CAMå›¾ç‰‡ï¼Œå°†é‡æ–°ç”Ÿæˆæ•°å€¼æ•°æ®è¿›è¡Œé¢‘ç‡åˆ†æ")
    
    return {'file_path': gradcam_file, 'regenerate_needed': True}


def generate_gradcam_for_sample(model, feature_extractor, grad_cam, device, 
                               cwt_features, stat_features, labels, sample_idx):
    """
    ä¸ºæŒ‡å®šæ ·æœ¬ç”ŸæˆGrad-CAM
    
    Args:
        model: è®­ç»ƒå¥½çš„æ¨¡å‹
        feature_extractor: ç‰¹å¾æå–å™¨
        grad_cam: GradCAMå®ä¾‹
        device: è®¡ç®—è®¾å¤‡
        cwt_features: CWTç‰¹å¾æ•°ç»„
        stat_features: ç»Ÿè®¡ç‰¹å¾æ•°ç»„
        labels: æ ‡ç­¾æ•°ç»„
        sample_idx: æ ·æœ¬ç´¢å¼•
        
    Returns:
        cam: Grad-CAMçƒ­åŠ›å›¾
        prediction: æ¨¡å‹é¢„æµ‹å€¼
    """
    # æå–æ ·æœ¬æ•°æ®
    cwt_sample = cwt_features[sample_idx]
    stat_sample = stat_features[sample_idx]
    sample_label = labels[sample_idx]
    
    # ç‰¹å¾æ ‡å‡†åŒ–
    norm_cwt, norm_stat = feature_extractor.transform(
        cwt_sample[np.newaxis, :, :], 
        stat_sample[np.newaxis, :]
    )
    
    # è½¬æ¢ä¸ºå¼ é‡
    cwt_tensor, stat_tensor, _ = feature_extractor.to_tensors(
        norm_cwt, norm_stat, np.array([sample_label])
    )
    
    cwt_tensor = cwt_tensor.to(device)
    stat_tensor = stat_tensor.to(device)
    
    # æ¨¡å‹é¢„æµ‹
    with torch.no_grad():
        prediction = model(cwt_tensor, stat_tensor)
        pred_value = prediction.item()
    
    # ç”ŸæˆGrad-CAM
    cam = grad_cam.generate_cam(cwt_tensor, stat_tensor, class_idx=0)
    
    return cam, pred_value


def create_frequency_aligned_plot(original_waveform, time_axis, cwt_features, gradcam, 
                                frequencies, sample_info, save_path):
    """
    åˆ›å»ºé¢‘ç‡å¯¹é½çš„ç»¼åˆåˆ†æå›¾
    
    Args:
        original_waveform: åŸå§‹æ³¢å½¢
        time_axis: æ—¶é—´è½´
        cwt_features: CWTç‰¹å¾
        gradcam: Grad-CAMçƒ­åŠ›å›¾
        frequencies: é¢‘ç‡è½´
        sample_info: æ ·æœ¬ä¿¡æ¯
        save_path: ä¿å­˜è·¯å¾„
    """
    # åˆ›å»ºå¤§å›¾
    fig = plt.figure(figsize=(30, 20))
    
    # ä¼˜åŒ–å¸ƒå±€
    gs = fig.add_gridspec(4, 3, 
                         height_ratios=[1.5, 1.3, 1.3, 1.0], 
                         width_ratios=[3.5, 3.5, 2.0],
                         hspace=0.4, wspace=0.3, 
                         top=0.93, bottom=0.08, left=0.06, right=0.96)
    
    # ä¸»æ ‡é¢˜
    fig.suptitle(f'Grad-CAMé¢‘ç‡åˆ†æ - æ–¹ä½ {sample_info["azimuth"]}, æ ·æœ¬ {sample_info["sample_num"]}\n'
                f'çœŸå®çªœæ§½æ¯”ä¾‹: {sample_info["true_label"]:.3f}, é¢„æµ‹å€¼: {sample_info["predicted_label"]:.3f}',
                fontsize=20, fontweight='bold', y=0.97)
    
    # 1. åŸå§‹æ³¢å½¢ (é¡¶éƒ¨ï¼Œè·¨2åˆ—)
    ax1 = fig.add_subplot(gs[0, :2])
    ax1.plot(time_axis * 1000, original_waveform, 'b-', linewidth=1.5, alpha=0.8)
    ax1.set_xlabel('æ—¶é—´ (ms)', fontsize=14)
    ax1.set_ylabel('å¹…å€¼', fontsize=14)
    ax1.set_title('é‡æ„çš„åŸå§‹å£°æ³¢æ³¢å½¢', fontsize=16, fontweight='bold', pad=20)
    ax1.grid(True, alpha=0.3)
    ax1.tick_params(axis='both', which='major', labelsize=12)
    
    # 2. CWTæ—¶é¢‘å›¾ (é¢‘ç‡è½´) - ç¬¬äºŒè¡Œå·¦
    ax2 = fig.add_subplot(gs[1, 0])
    time_samples = np.arange(cwt_features.shape[1])
    extent = [time_samples[0], time_samples[-1], frequencies[-1], frequencies[0]]
    
    im2 = ax2.imshow(cwt_features, aspect='auto', cmap='viridis', extent=extent)
    ax2.set_xlabel('æ—¶é—´æ ·æœ¬', fontsize=12)
    ax2.set_ylabel('é¢‘ç‡ (Hz)', fontsize=12)
    ax2.set_title('CWTæ—¶é¢‘ç‰¹å¾\n(é¢‘ç‡è½´)', fontsize=14, fontweight='bold')
    ax2.set_yscale('log')  # ä½¿ç”¨å¯¹æ•°åˆ»åº¦æ˜¾ç¤ºé¢‘ç‡
    
    # æ·»åŠ é¢œè‰²æ¡
    cbar2 = plt.colorbar(im2, ax=ax2, shrink=0.8)
    cbar2.set_label('CWTç³»æ•°å¹…å€¼', fontsize=11)
    
    # 3. Grad-CAMçƒ­åŠ›å›¾ (é¢‘ç‡è½´) - ç¬¬äºŒè¡Œä¸­
    ax3 = fig.add_subplot(gs[1, 1])
    im3 = ax3.imshow(gradcam, aspect='auto', cmap='jet', extent=extent, alpha=0.8)
    ax3.set_xlabel('æ—¶é—´æ ·æœ¬', fontsize=12)
    ax3.set_ylabel('é¢‘ç‡ (Hz)', fontsize=12)
    ax3.set_title('Grad-CAMæ³¨æ„åŠ›çƒ­åŠ›å›¾\n(é¢‘ç‡è½´)', fontsize=14, fontweight='bold')
    ax3.set_yscale('log')  # ä½¿ç”¨å¯¹æ•°åˆ»åº¦æ˜¾ç¤ºé¢‘ç‡
    
    # æ·»åŠ é¢œè‰²æ¡
    cbar3 = plt.colorbar(im3, ax=ax3, shrink=0.8)
    cbar3.set_label('æ³¨æ„åŠ›å¼ºåº¦', fontsize=11)
    
    # 4. é¢‘ç‡åˆ†æç»Ÿè®¡ (ç¬¬äºŒè¡Œå³)
    ax4 = fig.add_subplot(gs[1, 2])
    ax4.axis('off')
    
    # è®¡ç®—é¢‘ç‡åŸŸç»Ÿè®¡
    freq_attention = np.mean(gradcam, axis=1)
    max_attention_freq_idx = np.argmax(freq_attention)
    max_attention_freq = frequencies[max_attention_freq_idx]
    
    # è®¡ç®—æ—¶é—´åŸŸç»Ÿè®¡
    time_attention = np.mean(gradcam, axis=0)
    max_attention_time_idx = np.argmax(time_attention)
    max_attention_time = max_attention_time_idx  # æ ·æœ¬ç´¢å¼•
    
    stats_text = f"""é¢‘ç‡åˆ†æç»Ÿè®¡

é¢‘ç‡èŒƒå›´:
â€¢ æœ€é«˜é¢‘ç‡: {frequencies[0]:.0f} Hz
â€¢ æœ€ä½é¢‘ç‡: {frequencies[-1]:.0f} Hz
â€¢ é¢‘ç‡åˆ†è¾¨ç‡: {len(frequencies)} ä¸ªé¢‘æ®µ

Grad-CAMå…³é”®å‘ç°:
â€¢ æœ€å¤§æ³¨æ„åŠ›é¢‘ç‡: {max_attention_freq:.0f} Hz
â€¢ æœ€å¤§æ³¨æ„åŠ›æ—¶åˆ»: æ ·æœ¬ {max_attention_time}
â€¢ å¹³å‡æ³¨æ„åŠ›å¼ºåº¦: {np.mean(gradcam):.3f}
â€¢ æœ€å¤§æ³¨æ„åŠ›å¼ºåº¦: {np.max(gradcam):.3f}

é¢‘ç‡åŸŸèƒ½é‡åˆ†å¸ƒ:
â€¢ ä½é¢‘ (< 10kHz): {np.mean(freq_attention[frequencies < 10000]):.3f}
â€¢ ä¸­é¢‘ (10-50kHz): {np.mean(freq_attention[(frequencies >= 10000) & (frequencies < 50000)]):.3f}
â€¢ é«˜é¢‘ (â‰¥ 50kHz): {np.mean(freq_attention[frequencies >= 50000]):.3f}

çªœæ§½æ£€æµ‹ç›¸å…³:
â€¢ é¢„æµ‹å‡†ç¡®åº¦: {(1 - abs(sample_info["true_label"] - sample_info["predicted_label"]))*100:.1f}%
â€¢ æ ‡ç­¾ç±»å‹: {'é«˜çªœæ§½' if sample_info["true_label"] > 0.5 else 'ä½çªœæ§½'}
"""
    
    ax4.text(0.05, 0.95, stats_text, transform=ax4.transAxes,
             fontsize=10, verticalalignment='top', fontfamily='monospace',
             bbox=dict(boxstyle='round,pad=0.4', facecolor='lightblue', alpha=0.9))
    
    # 5. é¢‘ç‡åŸŸæ³¨æ„åŠ›åˆ†å¸ƒ (ç¬¬ä¸‰è¡Œå·¦)
    ax5 = fig.add_subplot(gs[2, 0])
    ax5.semilogx(frequencies, freq_attention, 'r-', linewidth=2, marker='o', markersize=3)
    ax5.fill_between(frequencies, freq_attention, alpha=0.3, color='red')
    ax5.set_xlabel('é¢‘ç‡ (Hz)', fontsize=12)
    ax5.set_ylabel('å¹³å‡æ³¨æ„åŠ›å¼ºåº¦', fontsize=12)
    ax5.set_title('é¢‘ç‡åŸŸæ³¨æ„åŠ›åˆ†å¸ƒ', fontsize=14, fontweight='bold')
    ax5.grid(True, alpha=0.3)
    
    # æ ‡è®°å…³é”®é¢‘ç‡ç‚¹
    ax5.axvline(max_attention_freq, color='red', linestyle='--', alpha=0.8, 
                label=f'æœ€å¤§æ³¨æ„åŠ›é¢‘ç‡: {max_attention_freq:.0f} Hz')
    ax5.legend()
    
    # 6. æ—¶é—´åŸŸæ³¨æ„åŠ›åˆ†å¸ƒ (ç¬¬ä¸‰è¡Œä¸­)
    ax6 = fig.add_subplot(gs[2, 1])
    time_samples_ms = time_samples * 1e-5 * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
    ax6.plot(time_samples_ms, time_attention, 'g-', linewidth=2)
    ax6.fill_between(time_samples_ms, time_attention, alpha=0.3, color='green')
    ax6.set_xlabel('æ—¶é—´ (ms)', fontsize=12)
    ax6.set_ylabel('å¹³å‡æ³¨æ„åŠ›å¼ºåº¦', fontsize=12)
    ax6.set_title('æ—¶é—´åŸŸæ³¨æ„åŠ›åˆ†å¸ƒ', fontsize=14, fontweight='bold')
    ax6.grid(True, alpha=0.3)
    
    # æ ‡è®°å…³é”®æ—¶é—´ç‚¹
    max_attention_time_ms = max_attention_time * 1e-5 * 1000
    ax6.axvline(max_attention_time_ms, color='green', linestyle='--', alpha=0.8, 
                label=f'æœ€å¤§æ³¨æ„åŠ›æ—¶åˆ»: {max_attention_time_ms:.2f} ms')
    ax6.legend()
    
    # 7. å åŠ æ˜¾ç¤º (ç¬¬ä¸‰è¡Œå³)
    ax7 = fig.add_subplot(gs[2, 2])
    # æ˜¾ç¤ºCWTä½œä¸ºèƒŒæ™¯
    ax7.imshow(cwt_features, aspect='auto', cmap='gray', extent=extent, alpha=0.6)
    # å åŠ Grad-CAM
    im7 = ax7.imshow(gradcam, aspect='auto', cmap='jet', extent=extent, alpha=0.7)
    ax7.set_xlabel('æ—¶é—´æ ·æœ¬', fontsize=11)
    ax7.set_ylabel('é¢‘ç‡ (Hz)', fontsize=11)
    ax7.set_title('CWT + Grad-CAM\nå åŠ æ˜¾ç¤º', fontsize=12, fontweight='bold')
    ax7.set_yscale('log')
    
    # 8. è¯¦ç»†åˆ†æç»“æœ (åº•éƒ¨ï¼Œè·¨3åˆ—)
    ax8 = fig.add_subplot(gs[3, :])
    ax8.axis('off')
    
    # æ‰¾å‡ºé«˜æ³¨æ„åŠ›çš„é¢‘ç‡-æ—¶é—´åŒºåŸŸ
    high_attention_threshold = np.percentile(gradcam, 90)
    high_attention_mask = gradcam > high_attention_threshold
    high_attention_coords = np.where(high_attention_mask)
    
    if len(high_attention_coords[0]) > 0:
        top_freq_indices = high_attention_coords[0][:10]  # å‰10ä¸ª
        top_time_indices = high_attention_coords[1][:10]
        
        analysis_text = "ğŸ¯ é«˜æ³¨æ„åŠ›åŒºåŸŸåˆ†æ (å‰10ä¸ªå…³é”®åŒºåŸŸ):\n\n"
        for i, (freq_idx, time_idx) in enumerate(zip(top_freq_indices, top_time_indices)):
            freq_val = frequencies[freq_idx]
            time_val = time_idx * 1e-5 * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
            attention_val = gradcam[freq_idx, time_idx]
            analysis_text += f"åŒºåŸŸ {i+1}: é¢‘ç‡ {freq_val:.0f} Hz, æ—¶é—´ {time_val:.2f} ms, æ³¨æ„åŠ› {attention_val:.3f}\n"
    else:
        analysis_text = "æœªæ£€æµ‹åˆ°æ˜¾è‘—çš„é«˜æ³¨æ„åŠ›åŒºåŸŸ"
    
    analysis_text += f"\n\nğŸ” ç‰©ç†è§£é‡Š:\n"
    analysis_text += f"â€¢ ä½é¢‘å…³æ³¨ (< 10kHz): å¯èƒ½å¯¹åº”æ°´æ³¥-å¥—ç®¡ç•Œé¢åå°„\n"
    analysis_text += f"â€¢ ä¸­é¢‘å…³æ³¨ (10-50kHz): å¯èƒ½å¯¹åº”å¥—ç®¡æ³¢ä¼ æ’­ç‰¹å¾\n"  
    analysis_text += f"â€¢ é«˜é¢‘å…³æ³¨ (â‰¥ 50kHz): å¯èƒ½å¯¹åº”ç›´è¾¾æ³¢å’Œæ•£å°„ä¿¡å·\n"
    analysis_text += f"â€¢ æ—¶é—´æ—©æœŸå…³æ³¨: ç›´è¾¾æ³¢å’Œå¼ºåå°„ä¿¡å·\n"
    analysis_text += f"â€¢ æ—¶é—´åæœŸå…³æ³¨: å¤šæ¬¡åå°„å’Œç»•å°„ä¿¡å·"
    
    ax8.text(0.02, 0.9, analysis_text, transform=ax8.transAxes,
             fontsize=12, verticalalignment='top', fontfamily='monospace',
             bbox=dict(boxstyle='round,pad=0.5', facecolor='lightyellow', alpha=0.9))
    
    plt.tight_layout()
    plt.savefig(save_path, dpi=150, bbox_inches='tight')
    plt.close()
    
    print(f"âœ… é¢‘ç‡åˆ†æå›¾ä¿å­˜åˆ°: {save_path}")


def analyze_sample_with_frequency(model, feature_extractor, grad_cam, device,
                                 azimuth, sample_idx, processed_data, save_dir):
    """
    åˆ†æå•ä¸ªæ ·æœ¬çš„é¢‘ç‡ç‰¹å¾
    
    Args:
        model: è®­ç»ƒå¥½çš„æ¨¡å‹
        feature_extractor: ç‰¹å¾æå–å™¨  
        grad_cam: GradCAMå®ä¾‹
        device: è®¡ç®—è®¾å¤‡
        azimuth: æ–¹ä½æ ‡è¯†ç¬¦
        sample_idx: æ ·æœ¬ç´¢å¼•
        processed_data: é¢„å¤„ç†æ•°æ®
        save_dir: ä¿å­˜ç›®å½•
        
    Returns:
        analysis_result: åˆ†æç»“æœå­—å…¸
    """
    print(f"ğŸ” åˆ†ææ–¹ä½ {azimuth} çš„æ ·æœ¬ {sample_idx}...")
    
    try:
        # æå–æ•°æ®
        cwt_features = processed_data['cwt_features']
        stat_features = processed_data['stat_features']
        labels = processed_data['labels']
        
        cwt_sample = cwt_features[sample_idx]
        stat_sample = stat_features[sample_idx]
        sample_label = labels[sample_idx]
        
        # ç”ŸæˆGrad-CAM
        cam, pred_value = generate_gradcam_for_sample(
            model, feature_extractor, grad_cam, device,
            cwt_features, stat_features, labels, sample_idx
        )
        
        # é‡æ„åŸå§‹æ³¢å½¢
        original_waveform, time_axis = reconstruct_original_waveform(
            cwt_sample, stat_sample, 
            {'true_label': sample_label, 'predicted_label': pred_value}
        )
        
        # è®¡ç®—é¢‘ç‡è½´
        scales = np.arange(1, cwt_sample.shape[0] + 1)
        frequencies = scale_to_frequency(scales, sampling_period=1e-5, wavelet='morl')
        
        # æ ·æœ¬ä¿¡æ¯
        sample_info = {
            'azimuth': azimuth,
            'sample_num': sample_idx,
            'true_label': sample_label,
            'predicted_label': pred_value
        }
        
        # åˆ›å»ºå¯è§†åŒ–
        save_path = os.path.join(save_dir, f'frequency_analysis_{azimuth}_sample_{sample_idx}.png')
        
        create_frequency_aligned_plot(
            original_waveform, time_axis, cwt_sample, cam, 
            frequencies, sample_info, save_path
        )
        
        # è¿”å›åˆ†æç»“æœ
        return {
            'azimuth': azimuth,
            'sample_idx': sample_idx,
            'original_waveform': original_waveform,
            'time_axis': time_axis,
            'cwt_features': cwt_sample,
            'gradcam': cam,
            'frequencies': frequencies,
            'sample_info': sample_info,
            'visualization_path': save_path
        }
        
    except Exception as e:
        print(f"âŒ åˆ†ææ ·æœ¬ {sample_idx} æ—¶å‡ºé”™: {str(e)}")
        import traceback
        traceback.print_exc()
        return None


def main():
    """ä¸»å‡½æ•° - Grad-CAMé¢‘ç‡åˆ†æ"""
    print("=" * 80)
    print("ğŸ¯ GRAD-CAM é¢‘ç‡åˆ†æ")
    print("å°†å°ºåº¦è½´è½¬æ¢ä¸ºé¢‘ç‡è½´ï¼Œæå–åŸå§‹æ³¢å½¢ï¼Œæ—¶é—´å¯¹é½åˆ†æ")
    print("=" * 80)
    
    # åˆ›å»ºç»“æœç›®å½•
    save_dir = 'data/results/frequency_analysis'
    os.makedirs(save_dir, exist_ok=True)
    
    try:
        # åŠ è½½é…ç½®
        print("ğŸ“‹ åŠ è½½é…ç½®æ–‡ä»¶...")
        with open('configs/config.yaml', 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
        
        # åŠ è½½ç‰¹å¾æå–å™¨
        print("ğŸ”§ åŠ è½½ç‰¹å¾æå–å™¨...")
        with open('data/processed/full_feature_extractor.pkl', 'rb') as f:
            fe_params = pickle.load(f)
        
        feature_extractor = FeatureExtractor(normalization_method=fe_params['normalization_method'])
        feature_extractor.cwt_scaler = fe_params['cwt_scaler']
        feature_extractor.stat_scaler = fe_params['stat_scaler']
        feature_extractor.is_fitted = fe_params['is_fitted']
        
        # åŠ è½½æ¨¡å‹
        print("ğŸ¤– åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹...")
        model = HybridCNNModel(config_path='configs/config.yaml')
        device = get_device('configs/config.yaml')
        
        if device.type == 'cuda':
            model.load_state_dict(torch.load('data/processed/full_best_model.pth'))
        else:
            model.load_state_dict(torch.load('data/processed/full_best_model.pth', map_location=device))
        
        model.to(device)
        model.eval()
        
        print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼Œè®¾å¤‡: {device}")
        
        # åˆå§‹åŒ–Grad-CAM
        grad_cam = GradCAM(model, target_layer_name='cnn_branch.conv_layers.2')
        
        # åˆ†æç°æœ‰Grad-CAMç»“æœä¸­çš„æ ·æœ¬
        print("\nğŸ” åˆ†æç°æœ‰Grad-CAMç»“æœ...")
        
        # ä»ç°æœ‰çš„Grad-CAMç»“æœç›®å½•ä¸­æå–æ ·æœ¬ä¿¡æ¯
        gradcam_dir = 'data/results/full_gradcam'
        gradcam_files = [f for f in os.listdir(gradcam_dir) if f.startswith('gradcam_azimuth_') and f.endswith('.png')]
        
        print(f"æ‰¾åˆ° {len(gradcam_files)} ä¸ªç°æœ‰çš„Grad-CAMç»“æœæ–‡ä»¶")
        
        # è§£ææ–‡ä»¶åæå–æ–¹ä½å’Œæ ·æœ¬ä¿¡æ¯
        samples_to_analyze = []
        for filename in gradcam_files[:12]:  # åˆ†æå‰12ä¸ªæ ·æœ¬
            parts = filename.replace('.png', '').split('_')
            if len(parts) >= 4:
                azimuth = parts[2]
                sample_num = int(parts[4])
                samples_to_analyze.append((azimuth, sample_num))
        
        print(f"å°†åˆ†æä»¥ä¸‹æ ·æœ¬: {samples_to_analyze}")
        
        # é€ä¸ªåˆ†ææ ·æœ¬
        analysis_results = []
        processed_azimuths = {}
        
        for azimuth, sample_idx in samples_to_analyze:
            # åŠ è½½å¯¹åº”æ–¹ä½çš„æ•°æ®ï¼ˆé¿å…é‡å¤åŠ è½½ï¼‰
            if azimuth not in processed_azimuths:
                processed_data = load_processed_data(azimuth)
                if processed_data is None:
                    continue
                processed_azimuths[azimuth] = processed_data
            
            # åˆ†ææ ·æœ¬
            result = analyze_sample_with_frequency(
                model, feature_extractor, grad_cam, device,
                azimuth, sample_idx, processed_azimuths[azimuth], save_dir
            )
            
            if result is not None:
                analysis_results.append(result)
        
        # ç”Ÿæˆç»¼åˆæŠ¥å‘Š
        print("\nğŸ“Š ç”Ÿæˆç»¼åˆåˆ†ææŠ¥å‘Š...")
        generate_comprehensive_report(analysis_results, save_dir)
        
        print("\n" + "=" * 80)
        print("ğŸ‰ Grad-CAMé¢‘ç‡åˆ†æå®Œæˆ!")
        print("=" * 80)
        print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {save_dir}")
        print(f"ğŸ“ˆ æˆåŠŸåˆ†æ {len(analysis_results)} ä¸ªæ ·æœ¬")
        print(f"âœ… å°ºåº¦è½´å·²è½¬æ¢ä¸ºé¢‘ç‡è½´")
        print(f"âœ… åŸå§‹æ³¢å½¢å·²é‡æ„å¹¶å¯¹é½")
        print(f"âœ… ç‰©ç†è§£é‡Šå·²æ·»åŠ ")
        
        # æ˜¾ç¤ºåˆ†ææ‘˜è¦
        if analysis_results:
            print(f"\nğŸ“‹ åˆ†ææ‘˜è¦:")
            for result in analysis_results:
                info = result['sample_info']
                print(f"   â€¢ æ–¹ä½ {info['azimuth']}, æ ·æœ¬ {info['sample_num']}: "
                      f"çœŸå®æ ‡ç­¾ {info['true_label']:.3f}, é¢„æµ‹å€¼ {info['predicted_label']:.3f}")
        
    except Exception as e:
        print(f"âŒ åˆ†æè¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
        import traceback
        traceback.print_exc()


def generate_comprehensive_report(analysis_results, save_dir):
    """
    ç”Ÿæˆç»¼åˆåˆ†ææŠ¥å‘Š
    
    Args:
        analysis_results: åˆ†æç»“æœåˆ—è¡¨
        save_dir: ä¿å­˜ç›®å½•
    """
    report_path = os.path.join(save_dir, 'frequency_analysis_report.md')
    
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write("# Grad-CAMé¢‘ç‡åˆ†æç»¼åˆæŠ¥å‘Š\n\n")
        f.write(f"åˆ†ææ—¶é—´: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"åˆ†ææ ·æœ¬æ•°é‡: {len(analysis_results)}\n\n")
        
        f.write("## 1. åˆ†ææ¦‚è¿°\n\n")
        f.write("æœ¬æŠ¥å‘Šå°†ç°æœ‰çš„Grad-CAMç»“æœä¸­çš„å°ºåº¦è½´è½¬æ¢ä¸ºé¢‘ç‡è½´ï¼Œå¹¶é‡æ„äº†å¯¹åº”çš„åŸå§‹æ³¢å½¢è¿›è¡Œæ—¶é—´å¯¹é½åˆ†æã€‚\n\n")
        
        f.write("### æŠ€æœ¯è¦ç‚¹\n")
        f.write("- **å°ºåº¦åˆ°é¢‘ç‡è½¬æ¢**: ä½¿ç”¨Morletå°æ³¢çš„ä¸­å¿ƒé¢‘ç‡è¿›è¡Œè½¬æ¢\n")
        f.write("- **é¢‘ç‡è®¡ç®—å…¬å¼**: f = fc / (scale * dt), å…¶ä¸­fc=1.0, dt=1e-5s\n")
        f.write("- **æ³¢å½¢é‡æ„**: åŸºäºCWTç‰¹å¾å’Œç»Ÿè®¡ç‰¹å¾é‡æ„è¿‘ä¼¼åŸå§‹æ³¢å½¢\n")
        f.write("- **æ—¶é—´å¯¹é½**: ç¡®ä¿æ‰€æœ‰å›¾åƒæŒ‰ç›¸åŒçš„æ—¶é—´è½´å¯¹é½\n\n")
        
        if analysis_results:
            f.write("## 2. æ ·æœ¬åˆ†æç»“æœ\n\n")
            
            for i, result in enumerate(analysis_results, 1):
                info = result['sample_info']
                frequencies = result['frequencies']
                
                f.write(f"### æ ·æœ¬ {i}: æ–¹ä½ {info['azimuth']}, ç¼–å· {info['sample_num']}\n\n")
                f.write(f"- **çœŸå®çªœæ§½æ¯”ä¾‹**: {info['true_label']:.3f}\n")
                f.write(f"- **é¢„æµ‹çªœæ§½æ¯”ä¾‹**: {info['predicted_label']:.3f}\n")
                f.write(f"- **é¢„æµ‹è¯¯å·®**: {abs(info['true_label'] - info['predicted_label']):.3f}\n")
                f.write(f"- **é¢‘ç‡èŒƒå›´**: {frequencies[-1]:.0f} - {frequencies[0]:.0f} Hz\n")
                f.write(f"- **å¯è§†åŒ–æ–‡ä»¶**: `{os.path.basename(result['visualization_path'])}`\n\n")
        
        f.write("## 3. å…³é”®å‘ç°\n\n")
        f.write("### é¢‘ç‡åŸŸç‰¹å¾\n")
        f.write("- ä½é¢‘æ®µ (< 10 kHz): ä¸»è¦å¯¹åº”æ°´æ³¥-å¥—ç®¡ç•Œé¢çš„åå°„ä¿¡å·\n")
        f.write("- ä¸­é¢‘æ®µ (10-50 kHz): å¯¹åº”å¥—ç®¡æ³¢çš„ä¼ æ’­ç‰¹å¾\n")
        f.write("- é«˜é¢‘æ®µ (â‰¥ 50 kHz): å¯¹åº”ç›´è¾¾æ³¢å’Œé«˜é¢‘æ•£å°„ä¿¡å·\n\n")
        
        f.write("### æ—¶é—´åŸŸç‰¹å¾\n")
        f.write("- æ—©æœŸæ—¶é—´çª—: ç›´è¾¾æ³¢å’Œå¼ºåå°„ä¿¡å·å ä¸»å¯¼\n")
        f.write("- ä¸­æœŸæ—¶é—´çª—: å¥—ç®¡æ³¢å’Œç•Œé¢åå°„çš„ç»„åˆ\n")
        f.write("- åæœŸæ—¶é—´çª—: å¤šæ¬¡åå°„å’Œç»•å°„ä¿¡å·\n\n")
        
        f.write("## 4. ç‰©ç†è§£é‡Š\n\n")
        f.write("Grad-CAMæ³¨æ„åŠ›å›¾åœ¨é¢‘ç‡åŸŸçš„åˆ†å¸ƒåæ˜ äº†AIæ¨¡å‹å¯¹ä¸åŒç‰©ç†ç°è±¡çš„æ•æ„Ÿæ€§ï¼š\n\n")
        f.write("1. **æ°´æ³¥èƒ¶ç»“è´¨é‡æ£€æµ‹**: ä½é¢‘æ³¨æ„åŠ›å¼ºåº¦ä¸èƒ¶ç»“ç•Œé¢ç‰¹æ€§ç›¸å…³\n")
        f.write("2. **çªœæ§½æ£€æµ‹**: ç‰¹å®šé¢‘ç‡æ®µçš„æ³¨æ„åŠ›å¼‚å¸¸å¯èƒ½æŒ‡ç¤ºçªœæ§½å­˜åœ¨\n")
        f.write("3. **ä¿¡å·ä¼ æ’­è·¯å¾„**: æ—¶é¢‘æ³¨æ„åŠ›æ¨¡å¼åæ˜ å£°æ³¢ä¼ æ’­çš„ç‰©ç†è·¯å¾„\n\n")
        
        f.write("## 5. å»ºè®®\n\n")
        f.write("- é‡ç‚¹å…³æ³¨æ¨¡å‹åœ¨ç‰¹å®šé¢‘ç‡æ®µçš„æ³¨æ„åŠ›åˆ†å¸ƒ\n")
        f.write("- ç»“åˆæ—¶é—´å’Œé¢‘ç‡ä¿¡æ¯è¿›è¡Œç»¼åˆåˆ¤æ–­\n")
        f.write("- è€ƒè™‘ä¸åŒæ–¹ä½é—´çš„æ³¨æ„åŠ›æ¨¡å¼å·®å¼‚\n")
        f.write("- éªŒè¯é«˜æ³¨æ„åŠ›åŒºåŸŸä¸å·²çŸ¥ç‰©ç†ç°è±¡çš„å¯¹åº”å…³ç³»\n")
    
    print(f"ğŸ“ ç»¼åˆæŠ¥å‘Šç”Ÿæˆå®Œæˆ: {report_path}")


if __name__ == "__main__":
    # å¯¼å…¥pandasç”¨äºæ—¶é—´æˆ³
    try:
        import pandas as pd
    except ImportError:
        # å¦‚æœæ²¡æœ‰pandasï¼Œä½¿ç”¨datetime
        from datetime import datetime
        class pd:
            class Timestamp:
                @staticmethod
                def now():
                    return datetime.now()
                def strftime(self, fmt):
                    return datetime.now().strftime(fmt)
    
    main() 